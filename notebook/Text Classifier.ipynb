{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682a4507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 19:05:13.752760: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/frankzhuang/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, Conv1D, MaxPooling1D, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a759d18",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae5456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for parsing out data\n",
    "parse = string.punctuation + \"1234567890\\n\"\n",
    "colNames = [\"text\", \"class\"]\n",
    "\n",
    "pos = pd.DataFrame(columns = colNames)\n",
    "neg = pd.DataFrame(columns = colNames)\n",
    "\n",
    "#positive data\n",
    "pos_files = sorted(glob.glob(os.path.join(\"../data/pos/\", \"*.txt\")))\n",
    "posCount = 0\n",
    "for i in pos_files:\n",
    "    fp = open(i, \"r\")\n",
    "    data = fp.read()\n",
    "    fp.close()\n",
    "    data = data.translate(str.maketrans('','', parse))\n",
    "    pos.loc[posCount] = [data, 1]\n",
    "    posCount += 1\n",
    "\n",
    "#negative data\n",
    "neg_files = sorted(glob.glob(os.path.join(\"../data/neg/\", \"*.txt\")))\n",
    "negCount = 0\n",
    "for i in neg_files:\n",
    "    fp = open(i, \"r\")\n",
    "    data = fp.read()\n",
    "    fp.close()\n",
    "    data = data.translate(str.maketrans('','', parse))\n",
    "    neg.loc[negCount] = [data, 0]#0 used because of sigmoid [0, 1]\n",
    "    negCount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8afc51",
   "metadata": {},
   "source": [
    "Splitting Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30d07ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting train and test data 7:3\n",
    "data = pd.concat([pos, neg])\n",
    "train = pd.concat([pos.iloc[:700,:], neg.iloc[:700,:]])\n",
    "test = pd.concat([pos.iloc[700:,:], neg.iloc[700:,:]])\n",
    "trainLabel = pd.concat([pos.iloc[:700,1:], neg.iloc[:700,1:]])\n",
    "testLabel = pd.concat([pos.iloc[700:,1:], neg.iloc[700:,1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e507b9",
   "metadata": {},
   "source": [
    "Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ace732e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of unique words: 46830\n",
      "Average Review Length: 748.292\n",
      "Standard deviation: 328.70987015299676\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique = set()\n",
    "dataList = []\n",
    "for i in range(0, 2000):\n",
    "    words = data.iloc[i,0].split(\" \")\n",
    "    line = \"\"\n",
    "    for j in words:\n",
    "        if j != \"\":\n",
    "            unique.add(j)\n",
    "            line += (j + \" \")\n",
    "    dataList.append(line)\n",
    "print(\"Total num of unique words:\", len(unique))\n",
    "\n",
    "total = []\n",
    "for i in range(0, 2000):\n",
    "    total.append(len(data.iloc[i,0].split(\" \")))\n",
    "nptotal = np.asarray(total)\n",
    "print(\"Average Review Length:\", np.mean(nptotal))\n",
    "print(\"Standard deviation:\", np.std(nptotal))\n",
    "\n",
    "plt.hist(nptotal)\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Number of reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a213b1",
   "metadata": {},
   "source": [
    "Selecting a review length for padding and truncating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3850d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852\n"
     ]
    }
   ],
   "source": [
    "dataLengths = []\n",
    "\n",
    "trainWords = [] #for tokenization\n",
    "for i in range(0, len(train)):\n",
    "    dataLengths.append(len(train.iloc[i,0].split(\" \")))\n",
    "    words = train.iloc[i,0].split(\" \")\n",
    "    line = \"\"\n",
    "    for j in words:\n",
    "        if j != \"\":\n",
    "            unique.add(j)\n",
    "            line += (j + \" \")\n",
    "    trainWords.append(line)\n",
    "\n",
    "testWords = [] #for tokenization\n",
    "for i in range(0, len(test.index)):\n",
    "    dataLengths.append(len(test.iloc[i,0].split(\" \")))\n",
    "    words = test.iloc[i,0].split(\" \")\n",
    "    line = \"\"\n",
    "    for j in words:\n",
    "        if j != \"\":\n",
    "            unique.add(j)\n",
    "            line += (j + \" \")\n",
    "    testWords.append(line)\n",
    "testLabel = test[\"class\"]\n",
    "\n",
    "dataLengths = sorted(dataLengths)\n",
    "maxLength = dataLengths[int(.7 * len(dataLengths))]\n",
    "print(maxLength)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83acbe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the training data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dataList)\n",
    "wordIndex = tokenizer.word_index\n",
    "trainSequences = tokenizer.texts_to_sequences(trainWords)\n",
    "testSequences = tokenizer.texts_to_sequences(testWords)\n",
    "\n",
    "#padding and truncating\n",
    "trainPadded = pad_sequences(trainSequences, maxlen = maxLength, padding='post', truncating='post')\n",
    "testPadded = pad_sequences(testSequences, maxlen = maxLength, padding='post', truncating='post')\n",
    "\n",
    "#only interested in the top 5000 words\n",
    "trainPadded[trainPadded >= 5000] = 0\n",
    "testPadded[testPadded >= 5000] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da375f7c",
   "metadata": {},
   "source": [
    "Model 1: Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d97b950d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 19:05:22.767027: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "140/140 [==============================] - 3s 16ms/step - loss: 0.6967 - accuracy: 0.5207\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.6576 - accuracy: 0.6143\n",
      "Train Accuracy: 91.214287\n",
      "Test Accuracy: 61.833334\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 32, input_length=maxLength))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(trainPadded, trainLabel, epochs=2, batch_size=10)\n",
    "loss, accuracy = model.evaluate(trainPadded, trainLabel, verbose=0)\n",
    "print('Train Accuracy: %f' % (accuracy*100))\n",
    "loss, accuracy = model.evaluate(testPadded, testLabel, verbose=0)\n",
    "print('Test Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e6a9ca",
   "metadata": {},
   "source": [
    "Model 2: One Dimensional Convolutional Neural Netword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1800ef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  2/140 [..............................] - ETA: 9s - loss: 0.6937 - accuracy: 0.5000  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 19:05:30.337831: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f7ade6acf50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-04 19:05:30.337871: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Host, Default Version\n",
      "2023-09-04 19:05:30.338157: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-04 19:05:30.355347: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 10s 62ms/step - loss: 0.6967 - accuracy: 0.4979\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 9s 62ms/step - loss: 0.6935 - accuracy: 0.5179\n",
      "Train Accuracy: 62.214285\n",
      "Test Accuracy: 48.500001\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 32, input_length=maxLength))\n",
    "model.add(Conv1D(filters = 32, kernel_size = 3, groups = 32))\n",
    "model.add(MaxPooling1D(strides = 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(trainPadded, trainLabel, epochs=2, batch_size=10)\n",
    "loss, accuracy = model.evaluate(trainPadded, trainLabel, verbose=0)\n",
    "print('Train Accuracy: %f' % (accuracy*100))\n",
    "loss, accuracy = model.evaluate(testPadded, testLabel, verbose=0)\n",
    "print('Test Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409016d",
   "metadata": {},
   "source": [
    "Model 3: Long Short-Term Memory Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5227ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "140/140 [==============================] - 18s 117ms/step - loss: 0.6925 - accuracy: 0.5221\n",
      "Epoch 2/50\n",
      "140/140 [==============================] - 28s 200ms/step - loss: 0.6866 - accuracy: 0.5393\n",
      "Epoch 3/50\n",
      "140/140 [==============================] - 64s 460ms/step - loss: 0.6396 - accuracy: 0.5871\n",
      "Epoch 4/50\n",
      "140/140 [==============================] - 64s 459ms/step - loss: 0.6127 - accuracy: 0.6136\n",
      "Epoch 5/50\n",
      "140/140 [==============================] - 75s 537ms/step - loss: 0.5951 - accuracy: 0.6150\n",
      "Epoch 6/50\n",
      "140/140 [==============================] - 62s 446ms/step - loss: 0.5680 - accuracy: 0.6050\n",
      "Epoch 7/50\n",
      "140/140 [==============================] - 38s 267ms/step - loss: 0.5598 - accuracy: 0.6107\n",
      "Epoch 8/50\n",
      "140/140 [==============================] - 22s 157ms/step - loss: 0.5701 - accuracy: 0.6014\n",
      "Epoch 9/50\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 0.5628 - accuracy: 0.6129\n",
      "Epoch 10/50\n",
      "140/140 [==============================] - 19s 132ms/step - loss: 0.5624 - accuracy: 0.6186\n",
      "Epoch 11/50\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 0.5611 - accuracy: 0.6200\n",
      "Epoch 12/50\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 0.5613 - accuracy: 0.6193\n",
      "Epoch 13/50\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 0.5577 - accuracy: 0.6143\n",
      "Epoch 14/50\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 0.5584 - accuracy: 0.6243\n",
      "Epoch 15/50\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 0.5578 - accuracy: 0.6329\n",
      "Epoch 16/50\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 0.5635 - accuracy: 0.6193\n",
      "Epoch 17/50\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 0.5617 - accuracy: 0.6143\n",
      "Epoch 18/50\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 0.5570 - accuracy: 0.6236\n",
      "Epoch 19/50\n",
      "140/140 [==============================] - 21s 150ms/step - loss: 0.5558 - accuracy: 0.6229\n",
      "Epoch 20/50\n",
      "140/140 [==============================] - 22s 161ms/step - loss: 0.5581 - accuracy: 0.6279\n",
      "Epoch 21/50\n",
      "140/140 [==============================] - 23s 162ms/step - loss: 0.5669 - accuracy: 0.6164\n",
      "Epoch 22/50\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 0.5619 - accuracy: 0.6136\n",
      "Epoch 23/50\n",
      "140/140 [==============================] - 21s 152ms/step - loss: 0.5583 - accuracy: 0.6271\n",
      "Epoch 24/50\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 0.5545 - accuracy: 0.6300\n",
      "Epoch 25/50\n",
      "140/140 [==============================] - 18s 127ms/step - loss: 0.5551 - accuracy: 0.6243\n",
      "Epoch 26/50\n",
      "140/140 [==============================] - 18s 127ms/step - loss: 0.5560 - accuracy: 0.6179\n",
      "Epoch 27/50\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 0.5496 - accuracy: 0.6336\n",
      "Epoch 28/50\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 0.5579 - accuracy: 0.6329\n",
      "Epoch 29/50\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 0.5550 - accuracy: 0.6257\n",
      "Epoch 30/50\n",
      "140/140 [==============================] - 20s 145ms/step - loss: 0.5502 - accuracy: 0.6336\n",
      "Epoch 31/50\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 0.6315 - accuracy: 0.6350\n",
      "Epoch 32/50\n",
      "140/140 [==============================] - 22s 160ms/step - loss: 0.5564 - accuracy: 0.6279\n",
      "Epoch 33/50\n",
      "140/140 [==============================] - 22s 155ms/step - loss: 0.5485 - accuracy: 0.6279\n",
      "Epoch 34/50\n",
      "140/140 [==============================] - 25s 180ms/step - loss: 0.5648 - accuracy: 0.6300\n",
      "Epoch 35/50\n",
      "140/140 [==============================] - 23s 163ms/step - loss: 0.5522 - accuracy: 0.6271\n",
      "Epoch 36/50\n",
      "140/140 [==============================] - 21s 150ms/step - loss: 0.5511 - accuracy: 0.6257\n",
      "Epoch 37/50\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 0.5503 - accuracy: 0.6350\n",
      "Epoch 38/50\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 0.5531 - accuracy: 0.6250\n",
      "Epoch 39/50\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 0.5501 - accuracy: 0.6343\n",
      "Epoch 40/50\n",
      "140/140 [==============================] - 21s 148ms/step - loss: 0.5440 - accuracy: 0.6414\n",
      "Epoch 41/50\n",
      "140/140 [==============================] - 21s 149ms/step - loss: 0.5608 - accuracy: 0.6371\n",
      "Epoch 42/50\n",
      "140/140 [==============================] - 22s 154ms/step - loss: 0.5486 - accuracy: 0.6386\n",
      "Epoch 43/50\n",
      "140/140 [==============================] - 22s 157ms/step - loss: 0.5411 - accuracy: 0.6464\n",
      "Epoch 44/50\n",
      "140/140 [==============================] - 22s 156ms/step - loss: 0.5457 - accuracy: 0.6407\n",
      "Epoch 45/50\n",
      "140/140 [==============================] - 21s 152ms/step - loss: 0.5474 - accuracy: 0.6371\n",
      "Epoch 46/50\n",
      "140/140 [==============================] - 21s 151ms/step - loss: 0.5435 - accuracy: 0.6379\n",
      "Epoch 47/50\n",
      "140/140 [==============================] - 22s 154ms/step - loss: 0.5543 - accuracy: 0.6464\n",
      "Epoch 48/50\n",
      "140/140 [==============================] - 24s 175ms/step - loss: 0.5469 - accuracy: 0.6357\n",
      "Epoch 49/50\n",
      "140/140 [==============================] - 27s 190ms/step - loss: 0.5430 - accuracy: 0.6429\n",
      "Epoch 50/50\n",
      "140/140 [==============================] - 31s 224ms/step - loss: 0.5394 - accuracy: 0.6514\n",
      "Train Accuracy: 65.071428\n",
      "Test Accuracy: 54.666668\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 32, input_length=maxLength))\n",
    "model.add(LSTM(32))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(trainPadded, trainLabel, epochs=50, batch_size=10)\n",
    "loss, accuracy = model.evaluate(trainPadded, trainLabel, verbose=0)\n",
    "print('Train Accuracy: %f' % (accuracy*100))\n",
    "loss, accuracy = model.evaluate(testPadded, testLabel, verbose=0)\n",
    "print('Test Accuracy: %f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
